<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Guillem Brasó</title>
  
  <meta name="author" content="Guillem Brasó">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="images/guillembraso.png" src="images/guillembraso.png">

</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Guillem Brasó</name>
              </p>
              <p>I am a second year PhD candidate working with <a href="https://dvl.in.tum.de/team/lealtaixe/">Laura Leal-Taixé</a> at the <a href="https://dvl.in.tum.de/">Dynamic Vision and Learning </a> group,  <a href="https://www.tum.de/">TU Munich</a>.
              </p>
              <p>
                Before starting my PhD, I obtained a Master's in Mathematics from <a href="https://www.tum.de/">TU Munich</a>, while working on Multi-Object Tracking at my current lab. Before that, I got a Bachelor in Mathematics from the <a href="https://www.ub.edu/web/portal/en/">University of Barcelona</a>. During my Bsc, I worked with <a href="https://algorismes.github.io/">Jordi Vitrià</a> on explainable machine learning.
              </p>

              <p>
                In my free time, I like to climb, play the piano, and cook.
              </p>
              <p style="text-align:center">
                <a href="mailto:gbrasoa@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/GuillemBrasoCV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.de/citations?user=0cXSWzcAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/guillembraso">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/guillembraso/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/guillembraso.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/guillembraso.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>News</heading>
                  <p>
                      <table style="width:100%; text-align: left;">
                          <tr>
                              <td> <strong>[March 2022]</strong> </td>
                              <td> We are organizing the <a href="https://motchallenge.net/workshops/bmtt2022">BMTT workshop</a> at <a href="https://cvpr2022.thecvf.com/">CVPR 2022</a>. Check out our synth2real chalenges for tracking!</td>
                          </tr>
                          <tr>
                            <td> <strong>[March 2022]</strong> </td>
                            <td> Just created this website!</td>
                        </tr>
                      </table>
                  </p>
              </td>
          </tr>
      </tbody></table>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
              I have a general interest in Machine Learning and Computer Vision. Some of the tasks I focus on are  detection, segmentation, tracking and human pose estimation. I am also broadly interested in leveraging ideas from classical graph-based approaches and optimization in combination with deep learning to solve vision problems.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/centergroup.png" alt="blind-date" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://drive.google.com/file/d/1PQjzKgFcrAesMIDJr-WDlCwuGUxZJZwO/view?usp=sharing">
                <papertitle>The Center of Attention: Center-Keypoint Attention for Multi-Person Pose Estimation</papertitle>
              </a>
              <br>
             <strong>Guillem Brasó</strong>, Nikita Kister, Laura Leal-Taixé 
              <br>
              <strong>ICCV 2021 </strong>
              <p> We propose an multi-head attention-based framework for end-to-end bottom-up multi-person pose estimation. Our main idea is to detect both keypoints and object centers, and use cross-attention among them to group keypoints into human poses.</p>

                                                  
              <a href="https://arxiv.org/abs/2110.05132">paper</a> |                                     
              <a href="https://www.youtube.com/watch?v=i4zFdz-ZzjM">video</a> |
              <a href="https://github.com/dvl-tum/center-group" type="text/html">code</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/motsynth_teaser2.png" alt="blind-date" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://drive.google.com/file/d/1PQjzKgFcrAesMIDJr-WDlCwuGUxZJZwO/view?usp=sharing">
                <papertitle>MOTSynth: How Can Synthetic Data Help Pedestrian Detection and Tracking?</papertitle>
              </a>
              <br>
              Matteo Fabbri, <strong>Guillem Brasó</strong>,Gianluca Maugeri, Orcun Cetintas, Riccardo Gasparini, Aljosa Osep, Simone Calderara, Laura Leal-Taixe, Rita Cucchiara
              <br>
              <strong>ICCV 2021 </strong>
              <p> We introduce <em>MOTSynth</em>, a large-scale synthetic dataset for pedestrian tracking, detection, segmentation and 2D/3D keypoint estimation. We show that trackers and detectors trained on our dataset achieve impressive generalization results when tested on real data.</p>
          
              <a href="https://arxiv.org/abs/2108.09518">paper</a> |                                     
              <a href="https://motchallenge.net/data/MOTSynth-MOT-CVPR22/">dataset</a> |   
              <a href="https://www.youtube.com/watch?v=dc_Z1iCceL4">video</a> |
              <a href="https://github.com/dvl-tum/motsynth-baselines" type="text/html">code</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/neuralsolver.png" alt="blind-date" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://drive.google.com/file/d/1PQjzKgFcrAesMIDJr-WDlCwuGUxZJZwO/view?usp=sharing">
                <papertitle> Learning a Neural Solver for Multiple Object Tracking</papertitle>
              </a>
              <br>
             <strong>Guillem Brasó</strong>, Laura Leal-Taixé 
              <br>
              <strong>CVPR 2020 </strong> &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <p> Inspired by classical graph-based multi-object tracking methods, we propose a neural message passing framework for data association in multi-object tracking. We present the first graph-structured deep learning module for tracking, and achieve impressive results on the MOTChallenge benchmarks.</p>

                                                  
              <a href="https://arxiv.org/abs/1912.07515">paper</a> |                                     
              <a href="https://www.youtube.com/watch?v=YWEirYMaLWc">video</a> |
              <a href="https://github.com/dvl-tum/mot_neural_solver" type="text/html">code</a>
            </td>
          </tr>

        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
              <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                      This website's source code is from <a href="https://jonbarron.info/">Jon Barron</a>.
                  </p>
              </td>
          </tr>
      </tbody></table>

      </td>
    </tr>
  </table>
</body>

</html>
